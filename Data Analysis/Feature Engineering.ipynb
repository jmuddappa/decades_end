{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u> Situation </u></h2>\n",
    "\n",
    "Now I have a nice clean dataset with all entities resolved. However the meta-data is quite sparse. All I have is the source website, the ranking they gave (-1 if no ranking provided) and the title of the movie. Some preliminary data analysis follows here but first I'm going to augment the data using alternative data sources so that I can answer some more interesting questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T17:58:18.996502Z",
     "start_time": "2019-12-30T17:58:18.112411Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#!pip install git+https://github.com/alberanid/imdbpy\n",
    "#!pip install imdbpy\n",
    "from imdb import IMDb\n",
    "data = pd.read_csv(\"final.csv\", index_col = 'Index')\n",
    "pd.options.display.max_rows = 1000\n",
    "ia = IMDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u> Task 1 </u></h2>\n",
    "\n",
    "Let's augment the data with as many cool data sources as possible. The first step was to link all the movie titles I got with their IMDB ID. I used the IMDbpy API to do this. I got the docs off: https://readthedocs.org/projects/imdbpy/downloads/pdf/latest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:50:52.409512Z",
     "start_time": "2019-12-30T18:48:43.588Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "imdb_dict = dict((title, (None, None)) for title in data.Title)\n",
    "for movie, _ in imdb_dict.items():\n",
    "    imdb_movies = ia.search_movie(movie)\n",
    "    for i in range(len(imdb_movies)):\n",
    "        print(movie + \" \" + str(imdb_movies[i]) + \" \" + str(imdb_movies[i]['year']))\n",
    "        choice = input(\"Correct title?: \")\n",
    "        if choice == 'y':\n",
    "            imdb_dict[movie] = (imdb_movies[i].movieID, imdb_movies[i]['year'])\n",
    "            break\n",
    "\n",
    "imdb_df = pd.DataFrame()\n",
    "imdb_list = list()\n",
    "for key, value in imdb_dict.items():\n",
    "    movie = key\n",
    "    imdb_id, year = value\n",
    "    imdb_list.append([movie, imdb_id, year])\n",
    "imdb_df = imdb_df.append(imdb_list)\n",
    "imdb_df.columns = ['My_Title', 'IMDB_ID', 'Year']\n",
    "imdb_df.head()\n",
    "imdb_df.to_csv('imdb.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a nice exercise in fact checking all my data. I found a few inconsistencies where ampersands were dropped from the title like stan ollie -> stan & ollie. Now with the IMDB IDs I can pull out a wealth of information! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:01:00.793881Z",
     "start_time": "2019-12-30T18:00:58.447406Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': ['original title',\n",
       "  'cast',\n",
       "  'genres',\n",
       "  'runtimes',\n",
       "  'countries',\n",
       "  'country codes',\n",
       "  'language codes',\n",
       "  'color info',\n",
       "  'aspect ratio',\n",
       "  'sound mix',\n",
       "  'box office',\n",
       "  'certificates',\n",
       "  'original air date',\n",
       "  'rating',\n",
       "  'votes',\n",
       "  'cover url',\n",
       "  'plot outline',\n",
       "  'languages',\n",
       "  'title',\n",
       "  'year',\n",
       "  'kind',\n",
       "  'directors',\n",
       "  'writers',\n",
       "  'producers',\n",
       "  'composers',\n",
       "  'cinematographers',\n",
       "  'editors',\n",
       "  'editorial department',\n",
       "  'casting directors',\n",
       "  'production designers',\n",
       "  'art directors',\n",
       "  'set decorators',\n",
       "  'costume designers',\n",
       "  'make up department',\n",
       "  'production managers',\n",
       "  'assistant directors',\n",
       "  'art department',\n",
       "  'sound department',\n",
       "  'special effects',\n",
       "  'visual effects',\n",
       "  'stunts',\n",
       "  'camera department',\n",
       "  'animation department',\n",
       "  'casting department',\n",
       "  'costume departmen',\n",
       "  'location management',\n",
       "  'music department',\n",
       "  'script department',\n",
       "  'transportation department',\n",
       "  'miscellaneous',\n",
       "  'thanks',\n",
       "  'akas',\n",
       "  'writer',\n",
       "  'director',\n",
       "  'top 250 rank',\n",
       "  'production companies',\n",
       "  'distributors',\n",
       "  'special effects companies',\n",
       "  'other companies'],\n",
       " 'plot': ['plot', 'synopsis']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = 1392190\n",
    "movie = ia.get_movie(ID)\n",
    "movie.infoset2keys\n",
    "#not all features always found in infoset2keys!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that I found interesring are selected in this features list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:01:00.811590Z",
     "start_time": "2019-12-30T18:01:00.798388Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['title',\n",
    "            'cast', \n",
    "            'genres',\n",
    "            'runtimes',\n",
    "            'box office',\n",
    "            'rating',\n",
    "            'votes',\n",
    "            'kind',\n",
    "            'directors',\n",
    "            'writers',\n",
    "            'producers',\n",
    "            'composers',\n",
    "            'cinematographers',\n",
    "            'editors',\n",
    "            'casting directors',\n",
    "            'top 250 rank',\n",
    "            'plot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:50:52.411498Z",
     "start_time": "2019-12-30T18:50:02.700Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reading the list produced in first block\n",
    "imdb_df = pd.read_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the API works is you send it the IMDB ID and it returns a set of keys that it has available. Not all movies have all the features in them, so I need to write a function that can check if the featuers exist in the set of keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:01:14.242581Z",
     "start_time": "2019-12-30T18:01:11.655284Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Mad Max: Fury Road\n",
      "\n",
      "cast\n",
      "[<Person id:0362766[http] name:_Tom Hardy_>, <Person id:0000234[http] name:_Charlize Theron_>, <Person id:0396558[http] name:_Nicholas Hoult_>, <Person id:0117412[http] name:_Hugh Keays-Byrne_>, <Person id:2890541[http] name:_Josh Helman_>, <Person id:0428923[http] name:_Nathan Jones_>, <Person id:2368789[http] name:_ZoÃ« Kravitz_>, <Person id:2492819[http] name:_Rosie Huntington-Whiteley_>, <Person id:2142336[http] name:_Riley Keough_>, <Person id:3880181[http] name:_Abbey Lee_>, <Person id:5196907[http] name:_Courtney Eaton_>, <Person id:0397398[http] name:_John Howard_>, <Person id:0141885[http] name:_Richard Carter_>, <Person id:5208473[http] name:_Iota_>, <Person id:0760151[http] name:_Angus Sampson_>, <Person id:0353228[http] name:_Jennifer Hagan_>, <Person id:0301885[http] name:_Megan Gale_>, <Person id:0415513[http] name:_Melissa Jaffer_>, <Person id:0432970[http] name:_Melita Jurisic_>, <Person id:0428143[http] name:_Gillian Jones_>, <Person id:0810456[http] name:_Joy Smithers_>, <Person id:0445826[http] name:_Antoinette Kellermann_>, <Person id:6400463[http] name:_Christina Koch_>, <Person id:7485089[http] name:_Jon Iles_>, <Person id:1889775[http] name:_Quentin Kenihan_>, <Person id:5795532[http] name:_Coco Jack Gillies_>, <Person id:2794184[http] name:_Chris Patton_>, <Person id:2961388[http] name:_Stephen Dunlevy_>, <Person id:0636280[http] name:_Richard Norton_>, <Person id:1399073[http] name:_Vincent Roxburgh_>, <Person id:0910539[http] name:_John Walton_>, <Person id:5042968[http] name:_Ben Smith-Petersen_>, <Person id:5153107[http] name:_Russ McCarroll_>, <Person id:3378815[http] name:_Judd Wild_>, <Person id:7319534[http] name:_Elizabeth Cunico_>, <Person id:1987652[http] name:_Greg van Borssum_>, <Person id:2293356[http] name:_Robert Jones_>, <Person id:1260450[http] name:_Sebastian Dickins_>, <Person id:0593256[http] name:_Darren Andrew Mitchell_>, <Person id:1992004[http] name:_Crusoe Kurddal_>, <Person id:7319536[http] name:_Shyan Tonga_>, <Person id:1478036[http] name:_Cass Cumerford_>, <Person id:7319537[http] name:_Albert Lee_>, <Person id:7319538[http] name:_Riley Paton_>, <Person id:7319539[http] name:_Ripley Voeten_>, <Person id:5408090[http] name:_Macyn Van Borssum_>, <Person id:5458958[http] name:_Hunter Stratton Boland_>, <Person id:7319540[http] name:_Nathan Jenkins_>, <Person id:7319541[http] name:_Fletcher Gill_>, <Person id:7319542[http] name:_Whiley Toll_>, <Person id:7523442[http] name:_Ferdinand Hengombe_>, <Person id:7523443[http] name:_Gadaffi Davsab_>, <Person id:7523444[http] name:_Noddy Alfred_>, <Person id:7523445[http] name:_Jackson Hengombe_>, <Person id:7523446[http] name:_Christian Fane_>, <Person id:7523447[http] name:_Callum Gallagher_>, <Person id:7523448[http] name:_Abel Hofflin_>, <Person id:1043022[http] name:_Lee Perry_>, <Person id:2842897[http] name:_Debra Ades_>, <Person id:6717768[http] name:_Toby Ayers_>, <Person id:6196569[http] name:_Rhavin Banda_>, <Person id:5605428[http] name:_Karl Heinz Barr_>, <Person id:3914852[http] name:_Alison Benstead_>, <Person id:6365880[http] name:_Craig Bourke_>, <Person id:6059574[http] name:_Nerida Bronwen_>, <Person id:2757001[http] name:_Will C._>, <Person id:0136563[http] name:_HÃ©lÃ¨ne Cardona_>, <Person id:6917668[http] name:_Jeremy Costello_>, <Person id:0971437[http] name:_Sandi Finlay_>, <Person id:5122842[http] name:_Gareth Hamilton-Foster_>, <Person id:8240131[http] name:_Dawn Hogan_>, <Person id:7421688[http] name:_Georgia Jarrett_>, <Person id:5810594[http] name:_Hiroshi Kasuga_>, <Person id:3838477[http] name:_Jack Kelly_>, <Person id:7604282[http] name:_Ryan Madden_>, <Person id:8028151[http] name:_Shuhei Ogawa_>, <Person id:8853224[http] name:_Benjamin W Sullivan_>, <Person id:5738849[http] name:_Vanessa Summerfield_>, <Person id:5480480[http] name:_Yassica Switakowski_>, <Person id:4667562[http] name:_Leanne Michelle Watson_>]\n",
      "\n",
      "genres\n",
      "['Action', 'Adventure', 'Sci-Fi', 'Thriller']\n",
      "\n",
      "runtimes\n",
      "['120']\n",
      "\n",
      "box office\n",
      "{'Budget': '$150,000,000 (estimated)', 'Cumulative Worldwide Gross': '$378,436,354'}\n",
      "\n",
      "rating\n",
      "8.1\n",
      "\n",
      "votes\n",
      "811479\n",
      "\n",
      "kind\n",
      "movie\n",
      "\n",
      "directors\n",
      "[<Person id:0004306[http] name:_George Miller_>]\n",
      "\n",
      "writers\n",
      "[<Person id:0004306[http] name:_George Miller_>, <Person id:0565068[http] name:_Brendan McCarthy_>, <Person id:0490147[http] name:_Nick Lathouris_>]\n",
      "\n",
      "producers\n",
      "[<Person id:0075732[http] name:_Bruce Berman_>, <Person id:0121694[http] name:_Graham Burke_>, <Person id:0002211[http] name:_Christopher DeFaria_>, <Person id:0389414[http] name:_Genevieve Hofmeyr_>, <Person id:0004306[http] name:_George Miller_>, <Person id:0593294[http] name:_Doug Mitchell_>, <Person id:6518391[http] name:_Steven Mnuchin_>, <Person id:0705360[http] name:_Holly Radcliffe_>, <Person id:0808498[http] name:_Iain Smith_>, <Person id:1562833[http] name:_Courtenay Valenti_>, <Person id:0900840[http] name:_P.J. Voeten_>]\n",
      "\n",
      "composers\n",
      "[<Person id:0432725[http] name:_Junkie XL_>]\n",
      "\n",
      "cinematographers\n",
      "[<Person id:0005868[http] name:_John Seale_>]\n",
      "\n",
      "editors\n",
      "[<Person id:0803459[http] name:_Margaret Sixel_>]\n",
      "\n",
      "casting directors\n",
      "[<Person id:0056969[http] name:_Nikki Barrett_>, <Person id:0006353[http] name:_Ronna Kress_>]\n",
      "\n",
      "top 250 rank\n",
      "207\n",
      "\n",
      "plot\n",
      "['In a post-apocalyptic wasteland, a woman rebels against a tyrannical ruler in search for her homeland with the aid of a group of female prisoners, a psychotic worshiper, and a drifter named Max.::Matthew Trahan', \"An apocalyptic story set in the furthest reaches of our planet, in a stark desert landscape where humanity is broken, and almost everyone is crazed fighting for the necessities of life. Within this world exist two rebels on the run who just might be able to restore order. There's Max, a man of action and a man of few words, who seeks peace of mind following the loss of his wife and child in the aftermath of the chaos. And Furiosa, a woman of action and a woman who believes her path to survival may be achieved if she can make it across the desert back to her childhood homeland.::Production\", 'In the stark desert wasteland populated by a broken humanity driven with survival and the unending ravage for gasoline, a loner named Max finds himself unwantedly caught in the middle of a chase while aiding the heroine Furiosa and her female companions. She struggles to return to her homeland and escape the clutches of a ruthless desert gang leader, Immortan Joe. With the harsh desert sands in front of them and marauders behind, only the maddest will prevail the storm.', \"The former policeman Max is captured by the War Boys tribe, commanded by the Immortal Joe and assigned to be blood donor for the Wat Boy Nux who is sick. Meanwhile Imperator Furiosa drives a tank truck to collect gasoline for Joe. However her true intention is to flee from the tyrannical Joe with his five women selected to breed hidden in the truck to her homeland. Immortal Joe commands a party to hunt down Furiosa and Max is chained to Nux's car. Furiosa heads the truck into a sand storm but Nux continues to pursue her. After the storm, Max succeeds to escape from the car and brings Nux chained with him. He sees Furiosa and the five wives and decides to flee in their truck; but there is a secret to operate the truck and he teams up with Furiosa, leaving Nux in the desert. When Joe's gang arrives, they retrieve Nux and follow Furiosa. Will Max and the women succeed in escaping from Joe's gang?::Claudio Carvalho, Rio de Janeiro, Brazil\", \"Years after the collapse of civilization, the tyrannical Immortan Joe enslaves apocalypse survivors inside the desert fortress the Citadel. When the warrior Imperator Furiosa leads the despot's five wives in a daring escape, she forges an alliance with Max Rockatansky, a loner and former captive. Fortified in the massive, armored truck the War Rig, they try to outrun the ruthless warlord and his henchmen in a deadly high-speed chase through the Wasteland.::Jwelch5742\", \"After a narrow escape in the barren deserts of the dystopian Wasteland, the solitary post-apocalyptic survivor, Max Rockatansky, struggles to stay one step ahead from the water-controlling overlord Immortan Joe's marauding gangs, the Wild Boys. However, Max will soon cross paths with one of Joe's elite lieutenants--the fearless warrior, Imperator Furiosa--who has just fled the Citadel in her heavily armoured War Rig truck, absconding with an irreplaceable quintet of wives. Now, the powerful tyrant and his hordes of delusional zealots are after the unlikely team of Max and Furiosa; however, before the unforgiving Wasteland's deadly immensity, who has what it takes to survive?::Nick Riganas\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ID in [1392190]:\n",
    "    movie = ia.get_movie(ID)\n",
    "    for feature in features:\n",
    "        if (feature in movie.infoset2keys['main']) or (feature in movie.infoset2keys['plot']):\n",
    "            print(feature)\n",
    "            print(movie[feature])\n",
    "            print()\n",
    "        else:\n",
    "            print(feature + \" not available\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directors, actors etc are lists contain the Person object. Here's how you unpack the object. Upon examining this feature, I realized that the only really interesting information is the name of the actor themselves, so I'll just change the actor field to only have actor names in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:01:32.301327Z",
     "start_time": "2019-12-30T18:01:32.285527Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0362766', 'Tom Hardy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['cast'][0].personID, movie['cast'][0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box office value is not consistent so I'm not going to make use of it. I can try scraping this value later from Mojo. \n",
    "\n",
    "https://github.com/situkun123/Moive_mojo_project/blob/master/Moive_mojo_project.ipynb\n",
    "\n",
    "For now, I'm focusing on adding the features I have. I'm going to use a nested dictionary to do this. Occasionally the API fails to fetch data and to catch that I used a try-except block. If any are found I can manually add them to the dictionary before I pickle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:01:51.421823Z",
     "start_time": "2019-12-30T18:01:51.415935Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#to find\n",
    "#imdb_dict_copy  = imdb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:50:52.380738Z",
     "start_time": "2019-12-30T18:35:18.233726Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting information for: melancholia\n",
      "0/427\n",
      "Collecting information for: mad max: fury road\n",
      "1/427\n",
      "Collecting information for: the tree of life\n",
      "2/427\n",
      "Collecting information for: the rider\n",
      "3/427\n",
      "Collecting information for: a separation\n",
      "4/427\n",
      "Collecting information for: moonlight\n",
      "5/427\n",
      "Collecting information for: the fits\n",
      "6/427\n",
      "Collecting information for: margaret\n",
      "7/427\n",
      "Collecting information for: spider-man: into the spider-verse\n",
      "8/427\n",
      "Collecting information for: the florida project\n",
      "9/427\n",
      "Collecting information for: actress\n",
      "10/427\n",
      "Collecting information for: its such a beautiful day\n",
      "11/427\n",
      "Collecting information for: hell or high water\n",
      "12/427\n",
      "Collecting information for: parasite\n",
      "13/427\n",
      "Collecting information for: under the skin\n",
      "14/427\n",
      "Collecting information for: the handmaiden\n",
      "15/427\n",
      "Collecting information for: cameraperson\n",
      "16/427\n",
      "Collecting information for: once upon a time in hollywood\n",
      "17/427\n",
      "Collecting information for: clouds of sils maria\n",
      "18/427\n",
      "Collecting information for: first reformed\n",
      "19/427\n",
      "Collecting information for: winter's bone\n",
      "20/427\n",
      "Collecting information for: dunkirk\n",
      "21/427\n",
      "Collecting information for: you were never really here\n",
      "22/427\n",
      "Collecting information for: the villainess\n",
      "23/427\n",
      "Collecting information for: holy motors\n",
      "24/427\n",
      "Collecting information for: the social network\n",
      "25/427\n",
      "Collecting information for: timbuktu\n",
      "26/427\n",
      "Collecting information for: this is not a film\n",
      "27/427\n",
      "Collecting information for: the master\n",
      "28/427\n",
      "Collecting information for: lincoln\n",
      "29/427\n",
      "Collecting information for: the babadook\n",
      "30/427\n",
      "Collecting information for: once upon a time in anatolia\n",
      "31/427\n",
      "Collecting information for: phoenix\n",
      "32/427\n",
      "Collecting information for: short term 12\n",
      "33/427\n",
      "Collecting information for: two days one night\n",
      "34/427\n",
      "Collecting information for: the favourite\n",
      "35/427\n",
      "Collecting information for: o.j.: made in america\n",
      "36/427\n",
      "Collecting information for: the act of killing\n",
      "37/427\n",
      "Collecting information for: madeline's madeline\n",
      "38/427\n",
      "Collecting information for: mother\n",
      "39/427\n",
      "Collecting information for: beginners\n",
      "40/427\n",
      "Collecting information for: john wick\n",
      "41/427\n",
      "Collecting information for: inside llewyn davis\n",
      "42/427\n",
      "Collecting information for: creed\n",
      "43/427\n",
      "Collecting information for: uncut gems\n",
      "44/427\n",
      "Collecting information for: a dark song\n",
      "45/427\n",
      "Collecting information for: eden\n",
      "46/427\n",
      "Collecting information for: my happy family\n",
      "47/427\n",
      "Collecting information for: the irishman\n",
      "48/427\n",
      "Collecting information for: toni erdmann\n",
      "49/427\n",
      "Collecting information for: ida\n",
      "50/427\n",
      "Collecting information for: popstar: never stop never stopping\n",
      "51/427\n",
      "Collecting information for: la la land\n",
      "52/427\n",
      "Collecting information for: get out\n",
      "53/427\n",
      "Collecting information for: spotlight\n",
      "54/427\n",
      "Collecting information for: stories we tell\n",
      "55/427\n",
      "Collecting information for: hereditary\n",
      "56/427\n",
      "Collecting information for: paddington 2\n",
      "57/427\n",
      "Collecting information for: moneyball\n",
      "58/427\n",
      "Collecting information for: black panther\n",
      "59/427\n",
      "Collecting information for: citizen four\n",
      "60/427\n",
      "Collecting information for: boyhood\n",
      "61/427\n",
      "Collecting information for: the wolf of wall street\n",
      "62/427\n",
      "Collecting information for: tangerine\n",
      "63/427\n",
      "Collecting information for: frances ha\n",
      "64/427\n",
      "Collecting information for: ex machina\n",
      "65/427\n",
      "Collecting information for: spring breakers\n",
      "66/427\n",
      "Collecting information for: her\n",
      "67/427\n",
      "Collecting information for: inside out\n",
      "68/427\n",
      "Collecting information for: thunder road\n",
      "69/427\n",
      "Collecting information for: swiss army man\n",
      "70/427\n",
      "Collecting information for: 1917\n",
      "71/427\n",
      "Collecting information for: the revenant\n",
      "72/427\n",
      "Collecting information for: inception\n",
      "73/427\n",
      "Collecting information for: roma\n",
      "74/427\n",
      "Collecting information for: foxtrot\n",
      "75/427\n",
      "Collecting information for: django unchained\n",
      "76/427\n",
      "Collecting information for: drive\n",
      "77/427\n",
      "Collecting information for: skyfall\n",
      "78/427\n",
      "Collecting information for: moana\n",
      "79/427\n",
      "Collecting information for: the witch\n",
      "80/427\n",
      "Collecting information for: nocturnal animals\n",
      "81/427\n",
      "Collecting information for: free solo\n",
      "82/427\n",
      "Collecting information for: deadpool\n",
      "83/427\n",
      "Collecting information for: interstellar\n",
      "84/427\n",
      "Collecting information for: take shelter\n",
      "85/427\n",
      "Collecting information for: guardians of the galaxy\n",
      "86/427\n",
      "Collecting information for: booksmart\n",
      "87/427\n",
      "Collecting information for: scott pilgrim vs the world\n",
      "88/427\n",
      "Collecting information for: gravity\n",
      "89/427\n",
      "Collecting information for: zero dark thirty\n",
      "90/427\n",
      "Collecting information for: the conjuring\n",
      "91/427\n",
      "Collecting information for: your name\n",
      "92/427\n",
      "Collecting information for: what we do in the shadows\n",
      "93/427\n",
      "Collecting information for: snowpiercer\n",
      "94/427\n",
      "Collecting information for: room\n",
      "95/427\n",
      "Collecting information for: toy story 3\n",
      "96/427\n",
      "Collecting information for: the farewell\n",
      "97/427\n",
      "Collecting information for: train to busan\n",
      "98/427\n",
      "Collecting information for: coco\n",
      "99/427\n",
      "Collecting information for: sing street\n",
      "100/427\n",
      "Collecting information for: avengers: endgame\n",
      "101/427\n",
      "Collecting information for: selma\n",
      "102/427\n",
      "Collecting information for: amour\n",
      "103/427\n",
      "Collecting information for: shoplifters\n",
      "104/427\n",
      "Collecting information for: sorry to bother you\n",
      "105/427\n",
      "Collecting information for: logan\n",
      "106/427\n",
      "Collecting information for: a quiet place\n",
      "107/427\n",
      "Collecting information for: bridesmaids\n",
      "108/427\n",
      "Collecting information for: prisoners\n",
      "109/427\n",
      "Collecting information for: the great beauty\n",
      "110/427\n",
      "Collecting information for: star wars: the last jedi\n",
      "111/427\n",
      "Collecting information for: first man\n",
      "112/427\n",
      "Collecting information for: if beale street could talk\n",
      "113/427\n",
      "Collecting information for: the big short\n",
      "114/427\n",
      "Collecting information for: minding the gap\n",
      "115/427\n",
      "Collecting information for: upstream color\n",
      "116/427\n",
      "Collecting information for: carol\n",
      "117/427\n",
      "Collecting information for: a star is born\n",
      "118/427\n",
      "Collecting information for: the shape of water\n",
      "119/427\n",
      "Collecting information for: burning\n",
      "120/427\n",
      "Collecting information for: brooklyn\n",
      "121/427\n",
      "Collecting information for: gone girl\n",
      "122/427\n",
      "Collecting information for: 12 years a slave\n",
      "123/427\n",
      "Collecting information for: before midnight\n",
      "124/427\n",
      "Collecting information for: good time\n",
      "125/427\n",
      "Collecting information for: birdman\n",
      "126/427\n",
      "Collecting information for: blade runner 2049\n",
      "127/427\n",
      "Collecting information for: moonrise kingdom\n",
      "128/427\n",
      "Collecting information for: phantom thread\n",
      "129/427\n",
      "Collecting information for: arrival\n",
      "130/427\n",
      "Collecting information for: whiplash\n",
      "131/427\n",
      "Collecting information for: the grand budapest hotel\n",
      "132/427\n",
      "Collecting information for: nightcrawler\n",
      "133/427\n",
      "Collecting information for: black swan\n",
      "134/427\n",
      "Collecting information for: call me by your name\n",
      "135/427\n",
      "Collecting information for: eighth grade\n",
      "136/427\n",
      "Collecting information for: lady bird\n",
      "137/427\n",
      "Collecting information for: a girl walks home alone at night\n",
      "138/427\n",
      "Collecting information for: senna\n",
      "139/427\n",
      "Collecting information for: attack the block\n",
      "140/427\n",
      "Collecting information for: bpm\n",
      "141/427\n",
      "Collecting information for: dredd\n",
      "142/427\n",
      "Collecting information for: youth\n",
      "143/427\n",
      "Collecting information for: the wailing\n",
      "144/427\n",
      "Collecting information for: sicario\n",
      "145/427\n",
      "Collecting information for: mission: impossible - fallout\n",
      "146/427\n",
      "Collecting information for: leave no trace\n",
      "147/427\n",
      "Collecting information for: inherent vice\n",
      "148/427\n",
      "Collecting information for: the turin horse\n",
      "149/427\n",
      "Collecting information for: monsters\n",
      "150/427\n",
      "Collecting information for: beasts of the southern wild\n",
      "151/427\n",
      "Collecting information for: cold war\n",
      "152/427\n",
      "Collecting information for: thor: ragnarok\n",
      "153/427\n",
      "Collecting information for: uncle boonmee who can recall his past lives\n",
      "154/427\n",
      "Collecting information for: the artist\n",
      "155/427\n",
      "Collecting information for: the lobster\n",
      "156/427\n",
      "Collecting information for: the lost city of z\n",
      "157/427\n",
      "Collecting information for: captain america: the winter soldier\n",
      "158/427\n",
      "Collecting information for: shame\n",
      "159/427\n",
      "Collecting information for: four lions\n",
      "160/427\n",
      "Collecting information for: the dark knight rises\n",
      "161/427\n",
      "Collecting information for: looper\n",
      "162/427\n",
      "Collecting information for: nocturama\n",
      "163/427\n",
      "Collecting information for: columbus\n",
      "164/427\n",
      "Collecting information for: american honey\n",
      "165/427\n",
      "Collecting information for: carlos\n",
      "166/427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting information for: kill list\n",
      "167/427\n",
      "Collecting information for: joker\n",
      "168/427\n",
      "Collecting information for: avengers: infinity war\n",
      "169/427\n",
      "Collecting information for: blue valentine\n",
      "170/427\n",
      "Collecting information for: blue is the warmest colour\n",
      "171/427\n",
      "Collecting information for: it follows\n",
      "172/427\n",
      "Collecting information for: star wars: the force awakens\n",
      "173/427\n",
      "Collecting information for: the raid\n",
      "174/427\n",
      "Collecting information for: son of saul\n",
      "175/427\n",
      "Collecting information for: miss bala\n",
      "176/427\n",
      "Collecting information for: the immigrant\n",
      "177/427\n",
      "Collecting information for: the comedy\n",
      "178/427\n",
      "Collecting information for: the arbor\n",
      "179/427\n",
      "Collecting information for: high life\n",
      "180/427\n",
      "Collecting information for: drug war\n",
      "181/427\n",
      "Collecting information for: weekend\n",
      "182/427\n",
      "Collecting information for: happy hour\n",
      "183/427\n",
      "Collecting information for: mudbound\n",
      "184/427\n",
      "Collecting information for: stranger by the lake\n",
      "185/427\n",
      "Collecting information for: computer chess\n",
      "186/427\n",
      "Collecting information for: mustang\n",
      "187/427\n",
      "Collecting information for: tabu\n",
      "188/427\n",
      "Collecting information for: force majeure\n",
      "189/427\n",
      "Collecting information for: right now wrong then\n",
      "190/427\n",
      "Collecting information for: the loneliest planet\n",
      "191/427\n",
      "Collecting information for: support the girls\n",
      "192/427\n",
      "Collecting information for: a ghost story\n",
      "193/427\n",
      "Collecting information for: her smell\n",
      "194/427\n",
      "Collecting information for: paterson\n",
      "195/427\n",
      "Collecting information for: green room\n",
      "196/427\n",
      "Collecting information for: marriage story\n",
      "197/427\n",
      "Collecting information for: leviathan\n",
      "198/427\n",
      "Collecting information for: magic mike xxl\n",
      "199/427\n",
      "Collecting information for: elle\n",
      "200/427\n",
      "Collecting information for: everyone else\n",
      "201/427\n",
      "Collecting information for: the duke of burgundy\n",
      "202/427\n",
      "Collecting information for: dogtooth\n",
      "203/427\n",
      "Collecting information for: meeks cutoff\n",
      "204/427\n",
      "Collecting information for: certified copy\n",
      "205/427\n",
      "Collecting information for: the look of silence\n",
      "206/427\n",
      "Collecting information for: manchester by the sea\n",
      "207/427\n",
      "Collecting information for: an elephant sitting still\n",
      "208/427\n",
      "Collecting information for: did you wonder who fired the gun\n",
      "209/427\n",
      "Collecting information for: the future\n",
      "210/427\n",
      "Collecting information for: somewhere\n",
      "211/427\n",
      "Collecting information for: lil quinquin\n",
      "212/427\n",
      "Collecting information for: film socialisme\n",
      "213/427\n",
      "Collecting information for: an oversimplification of her beauty\n",
      "214/427\n",
      "Collecting information for: coma\n",
      "215/427\n",
      "Collecting information for: red hook summer\n",
      "216/427\n",
      "Collecting information for: zama\n",
      "217/427\n",
      "Collecting information for: the mule\n",
      "218/427\n",
      "Collecting information for: it felt like love\n",
      "219/427\n",
      "Collecting information for: the last of the unjust\n",
      "220/427\n",
      "Collecting information for: in jackson heights\n",
      "221/427\n",
      "Collecting information for: a screaming man\n",
      "222/427\n",
      "Collecting information for: a quiet passion\n",
      "223/427\n",
      "Collecting information for: taxi\n",
      "224/427\n",
      "Collecting information for: let the sunshine in\n",
      "225/427\n",
      "Collecting information for: infinite football\n",
      "226/427\n",
      "Collecting information for: manuscripts don t burn\n",
      "227/427\n",
      "Collecting information for: a film unfinished\n",
      "228/427\n",
      "Collecting information for: the king's speech\n",
      "229/427\n",
      "Collecting information for: inside job\n",
      "230/427\n",
      "Collecting information for: western\n",
      "231/427\n",
      "Collecting information for: long day s journey into night\n",
      "232/427\n",
      "Collecting information for: uncertain\n",
      "233/427\n",
      "Collecting information for: national gallery\n",
      "234/427\n",
      "Collecting information for: the overnighters\n",
      "235/427\n",
      "Collecting information for: the tale of the princess kaguya\n",
      "236/427\n",
      "Collecting information for: gangs of wasseypur\n",
      "237/427\n",
      "Collecting information for: dead souls\n",
      "238/427\n",
      "Collecting information for: hard to be a god\n",
      "239/427\n",
      "Collecting information for: big men\n",
      "240/427\n",
      "Collecting information for: my perestroika\n",
      "241/427\n",
      "Collecting information for: american hustle\n",
      "242/427\n",
      "Collecting information for: i called him morgan\n",
      "243/427\n",
      "Collecting information for: the tale\n",
      "244/427\n",
      "Collecting information for: paths of the soul\n",
      "245/427\n",
      "Collecting information for: gett: the trial of viviane amsalem\n",
      "246/427\n",
      "Collecting information for: a prophet\n",
      "247/427\n",
      "Collecting information for: for sama\n",
      "248/427\n",
      "Collecting information for: gavagai\n",
      "249/427\n",
      "Collecting information for: a bread factory part one part two\n",
      "250/427\n",
      "Collecting information for: ex libris: the new york public library\n",
      "251/427\n",
      "Collecting information for: nostalgia for the light\n",
      "252/427\n",
      "Collecting information for: the gatekeepers\n",
      "253/427\n",
      "Collecting information for: they shall not grow old\n",
      "254/427\n",
      "Collecting information for: the souvenir\n",
      "255/427\n",
      "Collecting information for: tower\n",
      "256/427\n",
      "Collecting information for: one more time with feeling\n",
      "257/427\n",
      "Collecting information for: sherpa\n",
      "258/427\n",
      "Collecting information for: shoah: four sisters\n",
      "259/427\n",
      "Collecting information for: portrait of a lady on fire\n",
      "260/427\n",
      "Collecting information for: mr. turner\n",
      "261/427\n",
      "Collecting information for: 45 years\n",
      "262/427\n",
      "Collecting information for: amazing grace\n",
      "263/427\n",
      "Collecting information for: we were here\n",
      "264/427\n",
      "Collecting information for: faces places\n",
      "265/427\n",
      "Collecting information for: i am not your negro\n",
      "266/427\n",
      "Collecting information for: princess cyd\n",
      "267/427\n",
      "Collecting information for: dawson city: frozen time\n",
      "268/427\n",
      "Collecting information for: wonder woman\n",
      "269/427\n",
      "Collecting information for: 20 feet from stardom\n",
      "270/427\n",
      "Collecting information for: all is lost\n",
      "271/427\n",
      "Collecting information for: amy\n",
      "272/427\n",
      "Collecting information for: anomalisa\n",
      "273/427\n",
      "Collecting information for: ant-man and the wasp\n",
      "274/427\n",
      "Collecting information for: apollo 11\n",
      "275/427\n",
      "Collecting information for: argo\n",
      "276/427\n",
      "Collecting information for: ash is purest white\n",
      "277/427\n",
      "Collecting information for: baby driver\n",
      "278/427\n",
      "Collecting information for: a beautiful day in the neighborhood\n",
      "279/427\n",
      "Collecting information for: the big sick\n",
      "280/427\n",
      "Collecting information for: birds of passage\n",
      "281/427\n",
      "Collecting information for: blackfish\n",
      "282/427\n",
      "Collecting information for: blackkklansman\n",
      "283/427\n",
      "Collecting information for: bridge of spies\n",
      "284/427\n",
      "Collecting information for: bumblebee\n",
      "285/427\n",
      "Collecting information for: can you ever forgive me\n",
      "286/427\n",
      "Collecting information for: captain america: civil war\n",
      "287/427\n",
      "Collecting information for: captain phillips\n",
      "288/427\n",
      "Collecting information for: crazy rich asians\n",
      "289/427\n",
      "Collecting information for: dallas buyers club\n",
      "290/427\n",
      "Collecting information for: dawn of the planet of the apes\n",
      "291/427\n",
      "Collecting information for: the death of stalin\n",
      "292/427\n",
      "Collecting information for: the disaster artist\n",
      "293/427\n",
      "Collecting information for: doctor strange\n",
      "294/427\n",
      "Collecting information for: dolemite is my name\n",
      "295/427\n",
      "Collecting information for: don t think twice\n",
      "296/427\n",
      "Collecting information for: eye in the sky\n",
      "297/427\n",
      "Collecting information for: a fantastic woman\n",
      "298/427\n",
      "Collecting information for: fighting with my family\n",
      "299/427\n",
      "Collecting information for: finding dory\n",
      "300/427\n",
      "Collecting information for: ford v ferrari\n",
      "301/427\n",
      "Collecting information for: gloria\n",
      "302/427\n",
      "Collecting information for: the guilty\n",
      "303/427\n",
      "Collecting information for: harry potter and the deathly hallows - part 2\n",
      "304/427\n",
      "Collecting information for: the hate u give\n",
      "305/427\n",
      "Collecting information for: hidden figures\n",
      "306/427\n",
      "Collecting information for: honeyland\n",
      "307/427\n",
      "Collecting information for: how to train your dragon\n",
      "308/427\n",
      "Collecting information for: hunt for the wilderpeople\n",
      "309/427\n",
      "Collecting information for: hustlers\n",
      "310/427\n",
      "Collecting information for: i tonya\n",
      "311/427\n",
      "Collecting information for: incredibles 2\n",
      "312/427\n",
      "Collecting information for: isle of dogs\n",
      "313/427\n",
      "Collecting information for: john wick: chapter 3 - parabellum\n",
      "314/427\n",
      "Collecting information for: the jungle book\n",
      "315/427\n",
      "Collecting information for: kedi\n",
      "316/427\n",
      "Collecting information for: knives out\n",
      "317/427\n",
      "Collecting information for: kubo and the two strings\n",
      "318/427\n",
      "Collecting information for: the lego movie\n",
      "319/427\n",
      "Collecting information for: life itself\n",
      "320/427\n",
      "Collecting information for: the lighthouse\n",
      "321/427\n",
      "Collecting information for: live die repeat: edge of tomorrow\n",
      "322/427\n",
      "Collecting information for: logan lucky\n",
      "323/427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting information for: love & friendship\n",
      "324/427\n",
      "Collecting information for: lucky\n",
      "325/427\n",
      "Collecting information for: maiden\n",
      "326/427\n",
      "Collecting information for: the martian\n",
      "327/427\n",
      "Collecting information for: the avengers\n",
      "328/427\n",
      "Collecting information for: mcqueen\n",
      "329/427\n",
      "Collecting information for: mission: impossible - rogue nation\n",
      "330/427\n",
      "Collecting information for: mud\n",
      "331/427\n",
      "Collecting information for: my life as a zucchini\n",
      "332/427\n",
      "Collecting information for: the nice guys\n",
      "333/427\n",
      "Collecting information for: the old man & the gun\n",
      "334/427\n",
      "Collecting information for: paddington\n",
      "335/427\n",
      "Collecting information for: pain and glory\n",
      "336/427\n",
      "Collecting information for: the peanut butter falcon\n",
      "337/427\n",
      "Collecting information for: the post\n",
      "338/427\n",
      "Collecting information for: rocketman\n",
      "339/427\n",
      "Collecting information for: the salesman\n",
      "340/427\n",
      "Collecting information for: searching\n",
      "341/427\n",
      "Collecting information for: shaun the sheep movie\n",
      "342/427\n",
      "Collecting information for: shazam\n",
      "343/427\n",
      "Collecting information for: spider-man: far from home\n",
      "344/427\n",
      "Collecting information for: spider-man: homecoming\n",
      "345/427\n",
      "Collecting information for: spy\n",
      "346/427\n",
      "Collecting information for: stan & ollie\n",
      "347/427\n",
      "Collecting information for: starred up\n",
      "348/427\n",
      "Collecting information for: summer 1993\n",
      "349/427\n",
      "Collecting information for: things to come\n",
      "350/427\n",
      "Collecting information for: three billboards outside ebbing missouri\n",
      "351/427\n",
      "Collecting information for: three identical strangers\n",
      "352/427\n",
      "Collecting information for: toy story 4\n",
      "353/427\n",
      "Collecting information for: true grit\n",
      "354/427\n",
      "Collecting information for: us\n",
      "355/427\n",
      "Collecting information for: wadjda\n",
      "356/427\n",
      "Collecting information for: war for the planet of the apes\n",
      "357/427\n",
      "Collecting information for: weiner\n",
      "358/427\n",
      "Collecting information for: widows\n",
      "359/427\n",
      "Collecting information for: wildlife\n",
      "360/427\n",
      "Collecting information for: won t you be my neighbor\n",
      "361/427\n",
      "Collecting information for: x-men: days of future past\n",
      "362/427\n",
      "Collecting information for: zootopia\n",
      "363/427\n",
      "Collecting information for: the cabin in the woods\n",
      "364/427\n",
      "Collecting information for: shirkers\n",
      "365/427\n",
      "Collecting information for: only lovers left alive\n",
      "366/427\n",
      "Collecting information for: frozen\n",
      "367/427\n",
      "Collecting information for: the day he arrives\n",
      "368/427\n",
      "Collecting information for: field niggas\n",
      "369/427\n",
      "Collecting information for: heaven knows what\n",
      "370/427\n",
      "Collecting information for: like someone in love\n",
      "371/427\n",
      "Collecting information for: the missing picture\n",
      "372/427\n",
      "Collecting information for: sunset song\n",
      "373/427\n",
      "Collecting information for: a touch of sin\n",
      "374/427\n",
      "Collecting information for: universal soldier: day of reckoning\n",
      "375/427\n",
      "Collecting information for: unstoppable\n",
      "376/427\n",
      "Collecting information for: the wind rises\n",
      "377/427\n",
      "Collecting information for: world of tomorrow\n",
      "378/427\n",
      "Collecting information for: cave of forgotten dreams\n",
      "379/427\n",
      "Collecting information for: the guard\n",
      "380/427\n",
      "Collecting information for: ad astra\n",
      "381/427\n",
      "Collecting information for: 20th century women\n",
      "382/427\n",
      "Collecting information for: the selfish giant\n",
      "383/427\n",
      "Collecting information for: stoker\n",
      "384/427\n",
      "Collecting information for: boy\n",
      "385/427\n",
      "Collecting information for: the edge of seventeen\n",
      "386/427\n",
      "Collecting information for: annihilation\n",
      "387/427\n",
      "Collecting information for: midnight special\n",
      "388/427\n",
      "Collecting information for: young adult\n",
      "389/427\n",
      "Collecting information for: kick ass\n",
      "390/427\n",
      "Collecting information for: rogue one: a star wars story\n",
      "391/427\n",
      "Collecting information for: insidious\n",
      "392/427\n",
      "Collecting information for: of gods and men\n",
      "393/427\n",
      "Collecting information for: the secret in their eyes\n",
      "394/427\n",
      "Collecting information for: anthropocene: the human epoch\n",
      "395/427\n",
      "Collecting information for: the disappearance of eleanor rigby\n",
      "396/427\n",
      "Collecting information for: silence\n",
      "397/427\n",
      "Collecting information for: the queen of versailles\n",
      "398/427\n",
      "Collecting information for: personal shopper\n",
      "399/427\n",
      "Collecting information for: me and earl and the dying girl\n",
      "400/427\n",
      "Collecting information for: the hateful eight\n",
      "401/427\n",
      "Collecting information for: no home movie\n",
      "402/427\n",
      "Collecting information for: horse money\n",
      "403/427\n",
      "Collecting information for: lemonade\n",
      "404/427\n",
      "Collecting information for: hypernormalisation\n",
      "405/427\n",
      "Collecting information for: loves is the message the message is death\n",
      "406/427\n",
      "Collecting information for: certain women\n",
      "407/427\n",
      "Collecting information for: the grand bizarre\n",
      "408/427\n",
      "Collecting information for: on the beach at night alone\n",
      "409/427\n",
      "Collecting information for: monos\n",
      "410/427\n",
      "Collecting information for: climax\n",
      "411/427\n",
      "Collecting information for: beanpole\n",
      "412/427\n",
      "Collecting information for: the tribe\n",
      "413/427\n",
      "Collecting information for: loveless\n",
      "414/427\n",
      "Collecting information for: private life\n",
      "415/427\n",
      "Collecting information for: martha marcy may marlene\n",
      "416/427\n",
      "Collecting information for: the hunt\n",
      "417/427\n",
      "Collecting information for: no\n",
      "418/427\n",
      "Collecting information for: girlhood\n",
      "419/427\n",
      "Collecting information for: white material\n",
      "420/427\n",
      "Collecting information for: suspiria\n",
      "421/427\n",
      "Collecting information for: foxcatcher\n",
      "422/427\n",
      "Collecting information for: killing them softly\n",
      "423/427\n",
      "Collecting information for: enemy\n",
      "424/427\n",
      "Collecting information for: the assassin\n",
      "425/427\n",
      "Collecting information for: jackie\n",
      "426/427\n"
     ]
    }
   ],
   "source": [
    "def create_imdb_dict():\n",
    "    imdb_dict = dict()\n",
    "    err = []\n",
    "    for i in range(len(imdb_df)):\n",
    "        print(\"Collecting information for: \" + imdb_df.loc[i].My_Title)\n",
    "        print(str(i) + \"/\" + str(len(imdb_df)))\n",
    "        ID = imdb_df.loc[i].IMDB_ID\n",
    "        movie = ia.get_movie(ID)\n",
    "        imdb_dict[ID] = dict()\n",
    "        for feature in features:\n",
    "            if (feature in movie.infoset2keys['main']) or (feature in movie.infoset2keys['plot']):\n",
    "                try:\n",
    "                    imdb_dict[ID][feature] = movie[feature]\n",
    "                except:\n",
    "                    err.append(ID)\n",
    "    return imdb_dict, err\n",
    "#imdb_dict, err = create_imdb_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process takes a fairly long time so I'm pickling the dictionary in case the notebook crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:52:23.730204Z",
     "start_time": "2019-12-30T18:52:23.267514Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(imdb_dict , open(\"imdb.p\", \"wb\"))\n",
    "#imdb_dict = pickle.load(open( \"imdb.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see what one item in this dictionary looks like. Let's now engineer some better features before we add everything to one large dataframe.\n",
    "\n",
    "1. For actors, directors etc. I want to just have a list of names (not Person object) and maybe limit it say top 10 billed actors in the movie.\n",
    "\n",
    "2. For plot I want to use NLP techniques to extract important keywords. I can then one hot encode this.\n",
    "\n",
    "3. Finally one hot encode all list features.\n",
    "\n",
    "4. Runtimes to be just 1 value from a list\n",
    "\n",
    "The box office feature had inconsistent values as seen below. Some have the budget and gross, some just the opening weekend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:53:26.535770Z",
     "start_time": "2019-12-30T18:53:26.510089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melancholia\n",
      "{'Budget': '$7,400,000 (estimated)', 'Opening Weekend Denmark': 'DKK958,848, 29 May 2011'}\n",
      "Mad Max: Fury Road\n",
      "{'Budget': '$150,000,000 (estimated)', 'Cumulative Worldwide Gross': '$378,436,354'}\n",
      "The Tree of Life\n",
      "{'Budget': '$32,000,000 (estimated)', 'Opening Weekend United States': '$493,788, 30 May 2011', 'Cumulative Worldwide Gross': '$54,303,319, 27 Oct 2011'}\n",
      "The Rider\n",
      "{'Opening Weekend United States': '$42,244, 15 Apr 2018'}\n",
      "A Separation\n",
      "{'Budget': '$500,000 (estimated)', 'Opening Weekend Iran': '$100,000, 19 Mar 2011', 'Cumulative Worldwide Gross': '$24,426,169'}\n",
      "Moonlight\n",
      "{'Budget': '$1,500,000 (estimated)', 'Opening Weekend United States': '$1,488,740, 18 Nov 2016', 'Cumulative Worldwide Gross': '$55,561,162, 20 Mar 2017'}\n",
      "The Fits\n",
      "{'Opening Weekend United States': '$11,300, 05 Jun 2016'}\n",
      "Margaret\n",
      "{'Budget': '$14,000,000 (estimated)', 'Opening Weekend United States': '$7,525, 02 Oct 2011'}\n",
      "Spider-Man: Into the Spider-Verse\n",
      "{'Budget': '$90,000,000 (estimated)', 'Opening Weekend United States': '$35,363,376, 16 Dec 2018', 'Cumulative Worldwide Gross': '$375,540,831'}\n",
      "The Florida Project\n",
      "{'Budget': '$2,000,000 (estimated)', 'Opening Weekend United States': '$157,553, 08 Oct 2017'}\n"
     ]
    }
   ],
   "source": [
    "for key in imdb_dict.keys():\n",
    "    if 'box office' in imdb_dict[key]:\n",
    "        print(imdb_dict[key]['title'])\n",
    "        print(imdb_dict[key]['box office'])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T18:18:45.783590Z",
     "start_time": "2019-12-26T18:18:45.771005Z"
    }
   },
   "source": [
    "<h2><u> Task 2 </u></h2>\n",
    "Preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:54:04.674232Z",
     "start_time": "2019-12-30T18:54:04.644820Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Website</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>melancholia</td>\n",
       "      <td>vulture</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mad max: fury road</td>\n",
       "      <td>vulture</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the tree of life</td>\n",
       "      <td>vulture</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the rider</td>\n",
       "      <td>vulture</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a separation</td>\n",
       "      <td>vulture</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title  Website  Rank\n",
       "Index                                   \n",
       "0             melancholia  vulture     1\n",
       "1      mad max: fury road  vulture     2\n",
       "2        the tree of life  vulture     3\n",
       "3               the rider  vulture     4\n",
       "4            a separation  vulture     5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Question 1: </b> What were the top 10 movies mentioned across all the sources?\n",
    "\n",
    "<b>Answer:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:54:11.238058Z",
     "start_time": "2019-12-30T18:54:11.206044Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mad max: fury road</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonlight</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get out</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the social network</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inside llewyn davis</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boyhood</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady bird</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roma</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call me by your name</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parasite</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Website\n",
       "Title                        \n",
       "mad max: fury road         29\n",
       "moonlight                  28\n",
       "get out                    26\n",
       "the social network         22\n",
       "inside llewyn davis        19\n",
       "boyhood                    18\n",
       "lady bird                  18\n",
       "roma                       16\n",
       "call me by your name       15\n",
       "parasite                   15"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double square brackets to keep it as a dataframe\n",
    "#columns option is required when using double braces\n",
    "#have the column before the sum function in group_by\n",
    "data.groupby('Title')[['Website']].count().nlargest(columns = 'Website', n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay but some of the data was ranked and some unranked, let's see what lists emerge from the ranked lists and the unranked lists. To split them up I use the split-apply-combine pattern of pandas.\n",
    "\n",
    "<b> Question 2: </b> What were the top 10 movies mentioned across ranked and unranked sources?\n",
    "\n",
    "<b>Answer:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:54:25.234255Z",
     "start_time": "2019-12-30T18:54:25.201038Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>moonlight</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get out</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the social network</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boyhood</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady bird</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad max: fury road</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roma</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black panther</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inception</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Website\n",
       "Title                      \n",
       "moonlight                 9\n",
       "get out                   8\n",
       "the social network        8\n",
       "boyhood                   7\n",
       "lady bird                 7\n",
       "mad max: fury road        7\n",
       "roma                      7\n",
       "black panther             6\n",
       "her                       5\n",
       "inception                 5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_rank(x):\n",
    "    if x == -1: return 0\n",
    "    else: return 1\n",
    "\n",
    "data['is_ranked'] = data['Rank'].apply(lambda x: is_rank(x))\n",
    "ranked_data = data[data['is_ranked'] == 1]\n",
    "unranked_data = data[data['is_ranked'] == 0]\n",
    "unranked_data.groupby('Title')[['Website']].count().nlargest(columns = 'Website', n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T18:54:36.237217Z",
     "start_time": "2019-12-30T18:54:36.209384Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mad max: fury road</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moonlight</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get out</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inside llewyn davis</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the social network</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the master</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the act of killing</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the grand budapest hotel</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boyhood</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call me by your name</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Website\n",
       "Title                            \n",
       "mad max: fury road             22\n",
       "moonlight                      19\n",
       "get out                        18\n",
       "inside llewyn davis            14\n",
       "the social network             14\n",
       "the master                     13\n",
       "the act of killing             12\n",
       "the grand budapest hotel       12\n",
       "boyhood                        11\n",
       "call me by your name           11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_data.groupby('Title')[['Website']].count().nlargest(columns = 'Website', n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Question 3: </b> Who were the top actors, directors, writers etc.?\n",
    "\n",
    "<b>Answer:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:32:52.215579Z",
     "start_time": "2019-12-30T19:32:52.181555Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#function to get values of a certain key from a nested dictionary\n",
    "def top_n_list(dic, person_key, n, top_billing = 0):\n",
    "    people = []\n",
    "    if top_billing == 0:\n",
    "        for key in dic.keys():\n",
    "            if person_key in dic[key]:\n",
    "                for person in dic[key][person_key]:\n",
    "                    try:\n",
    "                        people.append((person.personID, person['name']))\n",
    "                    except:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for key in dic.keys():\n",
    "            if person_key in dic[key]:\n",
    "                for person in dic[key][person_key][0 : top_billing]:\n",
    "                    people.append((person.personID, person['name']))\n",
    "            else:\n",
    "                continue\n",
    "    count_people = Counter(people)\n",
    "    return count_people.most_common()[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:32:53.701556Z",
     "start_time": "2019-12-30T19:32:53.622460Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('5241466', 'Mark Falvo'), 22),\n",
       " (('7419291', 'Arnold Montey'), 14),\n",
       " (('0171625', 'Bern CollaÃ§o'), 14),\n",
       " (('0498278', 'Stan Lee'), 13),\n",
       " (('3485845', 'Adam Driver'), 11),\n",
       " (('0424060', 'Scarlett Johansson'), 10),\n",
       " (('5857646', 'Joseph Oliveira'), 10),\n",
       " (('0842770', 'Tilda Swinton'), 10),\n",
       " (('6768665', 'Patti Schellhaas'), 10),\n",
       " (('0000168', 'Samuel L. Jackson'), 10)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'cast', 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 4 actors are all extras actors! Luckily the cast is sorted by their billing order so I can use the top_n feature of my function to just select the top 20 billed actors from each movie which I think is a fair way to find the top actors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top actors of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:32:55.366557Z",
     "start_time": "2019-12-30T19:32:55.327790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0424060', 'Scarlett Johansson'), 10),\n",
       " (('3485845', 'Adam Driver'), 10),\n",
       " (('1209966', 'Oscar Isaac'), 8),\n",
       " (('0000168', 'Samuel L. Jackson'), 8),\n",
       " (('0842770', 'Tilda Swinton'), 8),\n",
       " (('0749263', 'Mark Ruffalo'), 7),\n",
       " (('1727304', 'Domhnall Gleeson'), 7),\n",
       " (('0331516', 'Ryan Gosling'), 7),\n",
       " (('1256532', 'Jon Bernthal'), 7),\n",
       " (('0262635', 'Chris Evans'), 7)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'cast', n = 10, top_billing = 20)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! The critic favorites of the decade!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top directors of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:17.687087Z",
     "start_time": "2019-12-30T19:33:17.668807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0898288', 'Denis Villeneuve'), 5),\n",
       " (('0634240', 'Christopher Nolan'), 4),\n",
       " (('0169806', 'Taika Waititi'), 4),\n",
       " (('0751577', 'Anthony Russo'), 4),\n",
       " (('0751648', 'Joe Russo'), 4),\n",
       " (('0000233', 'Quentin Tarantino'), 3),\n",
       " (('0000759', 'Paul Thomas Anderson'), 3),\n",
       " (('0000229', 'Steven Spielberg'), 3),\n",
       " (('0487166', 'Yorgos Lanthimos'), 3),\n",
       " (('1509478', 'Benny Safdie'), 3)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'directors', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top producers of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:28.115520Z",
     "start_time": "2019-12-30T19:33:28.092164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0748784', 'Scott Rudin'), 16),\n",
       " (('0498278', 'Stan Lee'), 16),\n",
       " (('5398118', 'Olivier PÃ¨re'), 16),\n",
       " (('2691892', 'Megan Ellison'), 13),\n",
       " (('0000093', 'Brad Pitt'), 12),\n",
       " (('0022285', 'Victoria Alonso'), 12),\n",
       " (('0195669', \"Louis D'Esposito\"), 12),\n",
       " (('0270559', 'Kevin Feige'), 12),\n",
       " (('0743882', 'Tessa Ross'), 11),\n",
       " (('4791912', 'Eli Bush'), 11)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'producers', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top composers of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:34.284315Z",
     "start_time": "2019-12-30T19:33:34.269665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0006035', 'Alexandre Desplat'), 10),\n",
       " (('0315974', 'Michael Giacchino'), 10),\n",
       " (('0001877', 'Hans Zimmer'), 8),\n",
       " (('0002354', 'John Williams'), 5),\n",
       " (('0001937', 'Marco Beltrami'), 5),\n",
       " (('0339351', 'Jonny Greenwood'), 4),\n",
       " (('0002353', 'Thomas Newman'), 4),\n",
       " (('0001980', 'Carter Burwell'), 4),\n",
       " (('2273444', 'Henry Jackman'), 4),\n",
       " (('0510533', 'Giong Lim'), 4)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'composers', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top cinematographers of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:42.225361Z",
     "start_time": "2019-12-30T19:33:42.209649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0005683', 'Roger Deakins'), 6),\n",
       " (('0523881', 'Emmanuel Lubezki'), 4),\n",
       " (('0393240', 'Kyung-pyo Hong'), 4),\n",
       " (('0494617', 'Yorick Le Saux'), 4),\n",
       " (('0568174', 'Michael McDonough'), 4),\n",
       " (('0887227', 'Hoyte Van Hoytema'), 4),\n",
       " (('0451787', 'Darius Khondji'), 4),\n",
       " (('1831620', 'Sean Porter'), 4),\n",
       " (('0006509', 'Rodrigo Prieto'), 4),\n",
       " (('1023204', 'Ben Davis'), 4)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'cinematographers', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top editors of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:50.698106Z",
     "start_time": "2019-12-30T19:33:50.686046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0907863', 'Joe Walker'), 6),\n",
       " (('0328557', 'Affonso GonÃ§alves'), 5),\n",
       " (('0809059', 'Lee Smith'), 5),\n",
       " (('0285701', 'Jeffrey Ford'), 5),\n",
       " (('0711235', 'Fred Raskin'), 4),\n",
       " (('0561430', 'Yorgos Mavropsaridis'), 4),\n",
       " (('0918733', 'Andrew Weisblum'), 4),\n",
       " (('2352780', 'Jennifer Lame'), 4),\n",
       " (('0773113', 'Matthew Schmidt'), 4),\n",
       " (('1477623', 'Nat Sanders'), 3)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'editors', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top writers of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:33:55.790610Z",
     "start_time": "2019-12-30T19:33:55.768885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0456158', 'Jack Kirby'), 13),\n",
       " (('0498278', 'Stan Lee'), 11),\n",
       " (('0094435', 'Bong Joon Ho'), 5),\n",
       " (('0634240', 'Christopher Nolan'), 5),\n",
       " (('1921680', 'Steve Englehart'), 5),\n",
       " (('0004056', 'Andrew Stanton'), 5),\n",
       " (('0800209', 'Joe Simon'), 5),\n",
       " (('0027572', 'Wes Anderson'), 5),\n",
       " (('0520488', 'Phil Lord'), 4),\n",
       " (('4401003', 'Derek Kolstad'), 4)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = top_n_list(imdb_dict, 'writers', n = 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Top genres of the decade</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:27:31.629803Z",
     "start_time": "2019-12-30T19:27:31.619944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action', 'Adventure', 'Sci-Fi', 'Thriller']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dict[1392190]['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T19:37:26.378898Z",
     "start_time": "2019-12-30T19:37:26.363831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 299),\n",
       " ('Comedy', 98),\n",
       " ('Thriller', 93),\n",
       " ('Adventure', 63),\n",
       " ('Crime', 63),\n",
       " ('Action', 60),\n",
       " ('Documentary', 59),\n",
       " ('Romance', 58),\n",
       " ('Sci-Fi', 54),\n",
       " ('Biography', 49)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = []\n",
    "for key in imdb_dict.keys():\n",
    "    for genre in imdb_dict[key]['genres']:\n",
    "        genres.append(genre)\n",
    "count_people = Counter(genres)\n",
    "count_people.most_common()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dramas just dominate the film market. I'm quite surprised that comedies was the second most repeated genre, just because of how badly pure comedy movies tend to get rated on IMDB and Rotten Tomatoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
